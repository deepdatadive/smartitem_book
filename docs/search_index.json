[
["index.html", "SMRT 1 Preface", " SMRT Chris Foster 2019-02-06 1 Preface This book is a compilation of different reseach pieces all compiled together into a single volume. The purpose of the volume is to provide a concise, research oriented view of the smart item and other accompanying item formats. Each chapter will be a different research topic and we will attempt to group similar research articles in close proximity to each other within the book. "],
["introduction-to-smart-items.html", "2 Introduction to Smart Items 2.1 Purpose of Building Smart Items 2.2 Smart Item Logic", " 2 Introduction to Smart Items Dave Really REally wants to be able to make a change to this text document. A SmartItem is first and foremost an item, used on exams to measure important skills. Like traditional items, it has an ID number, is stored on a computer, is evaluated like traditional items with expert reviews, and eventually response data from examinees. It can be used on any kind of test design, such as CAT, LOFT, etc. If and when it doesn’t function well, it can be repaired or deleted or retired. The main difference between a smart item and a normal item is that the smart item is written with three areas of expertise: Subject matter, item writing and programming. With a well written and specific objective, with the help of a programmer and enough content expertise it is possible to write a single item which can cover the entire range of an objective. With the help of a programmer an item writer can write a series of stems, options, correct responses and incorrect responses that can generate a large amount of potential item derivatives based on a single objective. This process creates an item that is less static than a single multiple choice item. In order better understand a smart item it is best to start with an example. An illustrativec example would come from an elementary math test. A single objective might be: Add two single digit numbers. There are only 10 single digit numbers (including 0) So really there is only (10!/ 2!(10-2)!) = 45 possible options as long as order doesn’t matter. Now, a single item writer could write all 45 items and cover the objective completely. However, it is also possible to write a simple program which generates all 45 possible questions. Now, for a fixed form test it would be likely that the item writer woudl not write all 45 options but instead write 2 or 3 of which one would be selected for the first form of the test while a different one might be selected for a second form. However, when administering a smart item to participants each participant would get a random stem and random options (including the correct option). Now, for a simple math objective it might not be necessary to write an algorithm that writes the 45 different possible stems for the objective. However, imagine an objective where there are 206 possible answers such as “Identify each bone in the human body.” Or perhaps there is an objective which asks participants to arrange 4 words in alphabetical order. The words can be anything in the human dictionary. Now there are 170,000 words in the english language and picking 4 leaves 3.479x10^19 possible options to completely cover the objective content and no item writer can write all of them and given current test construction methods there is no reason to do so. 2.1 Purpose of Building Smart Items 2.2 Smart Item Logic A first step to understanding the logic behind smart items is to understand the logic of randomization in experimentation. Sir Ronald Fisher Fisher (1925) outlined what is considered the cornerstone of experimental research today: randomization. Randomization has three primary purposes: It helps to distribute idosyncratic characteristics of participants to groups so that it does not bias the outcome. If participants could self select groups or were grouped based on characteristics than it could create systematic biases in the outcome based on participant characteristics. Randomization helps calculate unbiased estimate of error effects. IE: those effects not attributable to the manipulation of an independent variable Randomization helps ensure that error efects are statistically independent. Now, considering point #1 a bit more: Randomization helps ensure that within group variability is Independent and identically distributed (IID) or in other words, within group variability does not contain bias and is simply noise. Without randomization it could easily contain any number of biases which could decrease or increase the differnces between groups. It is impossible to list all possible systematic biases that could creep into an experiment. Maybe all college educated participants self select themselves into a specific group or one gender reacts differently to a group assignment than another. While other papers have talked in length about the importance of randomization in experimental design for the purposes of this section randomization removes systematic bias within group. One natural artifact of the randomization process is an increase in within-group variation. If participants are asigned to groups based on characterisitcs or allowed to self select, more similar participants will end up in the same group reducing the amount of variability in the group. While a decrease in within-group variability inevitibly increases the probability of a significant effect in an experiment, the significant effect may simply be due to a bias brought by the selection process… which simply shows the importance of randomization. Even though variation is introduced, results are more trustworthy. References "],
["domc-difficulty-variance.html", "3 DOMC Difficulty Variance 3.1 Initial Run 3.2 Item 10B_v1 3.3 Item 14b_v1 3.4 Item 14a_v1 3.5 Remove correct response 3.6 Item 10B_v1 3.7 Item 14b_v1 3.8 All Item Plots", " 3 DOMC Difficulty Variance 3.1 Initial Run Here is a document showing the results of item families derived from a single DOMC stem. Essentially we treat each possible combination of options as a differential question just to see the amount of variance from a single DOMC stem. In this first run we treat each different option combination as a different item, including those for people who never saw the correct response (making all these p-values 0) 3.2 Item 10B_v1 tenb_v1 = hp_items %&gt;% filter(item_id == &#39;10B_v1&#39;) kable(tenb_v1) item_id order p_value count 10B_v1 0 0.8950000 200 10B_v1 01 1.0000000 42 10B_v1 012 0.9677419 31 10B_v1 0123 1.0000000 40 10B_v1 01234 0.9876543 162 10B_v1 0124 0.9827586 58 10B_v1 013 0.9666667 30 10B_v1 0134 1.0000000 45 10B_v1 014 0.9629630 27 10B_v1 02 0.9365079 63 10B_v1 023 0.9487179 39 10B_v1 0234 0.9354839 62 10B_v1 024 0.9210526 38 10B_v1 03 0.9464286 56 10B_v1 034 0.9666667 30 10B_v1 04 0.9756098 41 10B_v1 1 0.0000000 21 10B_v1 12 0.0000000 6 10B_v1 123 0.0000000 8 10B_v1 1234 0.0000000 13 10B_v1 124 0.0000000 3 10B_v1 13 0.0000000 10 10B_v1 134 0.0000000 7 10B_v1 14 0.0000000 8 10B_v1 2 0.0000000 3 10B_v1 234 0.0000000 1 10B_v1 24 0.0000000 4 10B_v1 3 0.0000000 1 10B_v1 4 0.0000000 2 3.2.1 Histogram theme_update(plot.title = element_text(hjust = 0.5)) ggplot(tenb_v1, aes(x=p_value)) + geom_histogram(binwidth=.01) + labs(title = &quot;Item10B_v1&quot;) ## Item 10A_v1 tena_v1 = hp_items_mc %&gt;% filter(item_id == &#39;10A_v1&#39;) kable(tena_v1) item_id item_order p_value count 10A_v1 [0, 1, 2, 3, 4] 1.0000000 9 10A_v1 [0, 1, 2, 4, 3] 1.0000000 4 10A_v1 [0, 1, 3, 2, 4] 0.7500000 8 10A_v1 [0, 1, 3, 4, 2] 1.0000000 7 10A_v1 [0, 1, 4, 2, 3] 0.8750000 8 10A_v1 [0, 1, 4, 3, 2] 1.0000000 13 10A_v1 [0, 2, 1, 3, 4] 0.8333333 6 10A_v1 [0, 2, 1, 4, 3] 1.0000000 8 10A_v1 [0, 2, 3, 1, 4] 0.8235294 17 10A_v1 [0, 2, 3, 4, 1] 0.7142857 7 10A_v1 [0, 2, 4, 1, 3] 1.0000000 6 10A_v1 [0, 2, 4, 3, 1] 1.0000000 14 10A_v1 [0, 3, 1, 2, 4] 0.7142857 7 10A_v1 [0, 3, 1, 4, 2] 0.9375000 16 10A_v1 [0, 3, 2, 1, 4] 1.0000000 12 10A_v1 [0, 3, 2, 4, 1] 1.0000000 12 10A_v1 [0, 3, 4, 1, 2] 1.0000000 9 10A_v1 [0, 3, 4, 2, 1] 1.0000000 11 10A_v1 [0, 4, 1, 2, 3] 0.9166667 12 10A_v1 [0, 4, 1, 3, 2] 0.7777778 9 10A_v1 [0, 4, 2, 1, 3] 1.0000000 8 10A_v1 [0, 4, 2, 3, 1] 0.8888889 9 10A_v1 [0, 4, 3, 1, 2] 0.8333333 6 10A_v1 [0, 4, 3, 2, 1] 1.0000000 8 10A_v1 [1, 0, 2, 3, 4] 0.7500000 8 10A_v1 [1, 0, 2, 4, 3] 0.8750000 8 10A_v1 [1, 0, 3, 2, 4] 1.0000000 13 10A_v1 [1, 0, 3, 4, 2] 0.9090909 11 10A_v1 [1, 0, 4, 2, 3] 0.9166667 12 10A_v1 [1, 0, 4, 3, 2] 1.0000000 14 10A_v1 [1, 2, 0, 3, 4] 1.0000000 9 10A_v1 [1, 2, 0, 4, 3] 1.0000000 13 10A_v1 [1, 2, 3, 0, 4] 1.0000000 5 10A_v1 [1, 2, 3, 4, 0] 0.6000000 5 10A_v1 [1, 2, 4, 0, 3] 0.9285714 14 10A_v1 [1, 2, 4, 3, 0] 1.0000000 4 10A_v1 [1, 3, 0, 2, 4] 1.0000000 10 10A_v1 [1, 3, 0, 4, 2] 0.9090909 11 10A_v1 [1, 3, 2, 0, 4] 0.8571429 14 10A_v1 [1, 3, 2, 4, 0] 1.0000000 9 10A_v1 [1, 3, 4, 0, 2] 1.0000000 3 10A_v1 [1, 3, 4, 2, 0] 0.9090909 11 10A_v1 [1, 4, 0, 2, 3] 1.0000000 18 10A_v1 [1, 4, 0, 3, 2] 0.9000000 10 10A_v1 [1, 4, 2, 0, 3] 1.0000000 6 10A_v1 [1, 4, 2, 3, 0] 1.0000000 9 10A_v1 [1, 4, 3, 0, 2] 0.8461538 13 10A_v1 [1, 4, 3, 2, 0] 0.9000000 10 10A_v1 [2, 0, 1, 3, 4] 0.8571429 7 10A_v1 [2, 0, 1, 4, 3] 0.8461538 13 10A_v1 [2, 0, 3, 1, 4] 1.0000000 7 10A_v1 [2, 0, 3, 4, 1] 1.0000000 6 10A_v1 [2, 0, 4, 1, 3] 0.8888889 9 10A_v1 [2, 0, 4, 3, 1] 1.0000000 4 10A_v1 [2, 1, 0, 3, 4] 0.8750000 8 10A_v1 [2, 1, 0, 4, 3] 1.0000000 6 10A_v1 [2, 1, 3, 0, 4] 0.9166667 12 10A_v1 [2, 1, 3, 4, 0] 0.8181818 11 10A_v1 [2, 1, 4, 0, 3] 0.8333333 12 10A_v1 [2, 1, 4, 3, 0] 0.8000000 10 10A_v1 [2, 3, 0, 1, 4] 0.7777778 9 10A_v1 [2, 3, 0, 4, 1] 0.8571429 7 10A_v1 [2, 3, 1, 0, 4] 1.0000000 11 10A_v1 [2, 3, 1, 4, 0] 0.8750000 8 10A_v1 [2, 3, 4, 0, 1] 0.8333333 6 10A_v1 [2, 3, 4, 1, 0] 1.0000000 9 10A_v1 [2, 4, 0, 1, 3] 1.0000000 4 10A_v1 [2, 4, 0, 3, 1] 1.0000000 10 10A_v1 [2, 4, 1, 0, 3] 1.0000000 11 10A_v1 [2, 4, 1, 3, 0] 0.7647059 17 10A_v1 [2, 4, 3, 0, 1] 1.0000000 8 10A_v1 [2, 4, 3, 1, 0] 0.6000000 5 10A_v1 [3, 0, 1, 2, 4] 0.9285714 14 10A_v1 [3, 0, 1, 4, 2] 0.9285714 14 10A_v1 [3, 0, 2, 1, 4] 0.9166667 12 10A_v1 [3, 0, 2, 4, 1] 0.8750000 8 10A_v1 [3, 0, 4, 1, 2] 1.0000000 11 10A_v1 [3, 0, 4, 2, 1] 1.0000000 7 10A_v1 [3, 1, 0, 2, 4] 0.8333333 12 10A_v1 [3, 1, 0, 4, 2] 0.7777778 9 10A_v1 [3, 1, 2, 0, 4] 0.8333333 12 10A_v1 [3, 1, 2, 4, 0] 1.0000000 11 10A_v1 [3, 1, 4, 0, 2] 0.8666667 15 10A_v1 [3, 1, 4, 2, 0] 0.8333333 12 10A_v1 [3, 2, 0, 1, 4] 0.6000000 10 10A_v1 [3, 2, 0, 4, 1] 1.0000000 7 10A_v1 [3, 2, 1, 0, 4] 1.0000000 7 10A_v1 [3, 2, 1, 4, 0] 0.9166667 12 10A_v1 [3, 2, 4, 0, 1] 1.0000000 6 10A_v1 [3, 2, 4, 1, 0] 1.0000000 7 10A_v1 [3, 4, 0, 1, 2] 0.9000000 10 10A_v1 [3, 4, 0, 2, 1] 1.0000000 6 10A_v1 [3, 4, 1, 0, 2] 0.9000000 10 10A_v1 [3, 4, 1, 2, 0] 0.8000000 10 10A_v1 [3, 4, 2, 0, 1] 0.8333333 6 10A_v1 [3, 4, 2, 1, 0] 0.8750000 8 10A_v1 [4, 0, 1, 2, 3] 1.0000000 18 10A_v1 [4, 0, 1, 3, 2] 1.0000000 5 10A_v1 [4, 0, 2, 1, 3] 0.7142857 7 10A_v1 [4, 0, 2, 3, 1] 1.0000000 6 10A_v1 [4, 0, 3, 1, 2] 0.8181818 11 10A_v1 [4, 0, 3, 2, 1] 0.9375000 16 10A_v1 [4, 1, 0, 2, 3] 0.9166667 12 10A_v1 [4, 1, 0, 3, 2] 1.0000000 10 10A_v1 [4, 1, 2, 0, 3] 1.0000000 11 10A_v1 [4, 1, 2, 3, 0] 1.0000000 7 10A_v1 [4, 1, 3, 0, 2] 1.0000000 3 10A_v1 [4, 1, 3, 2, 0] 1.0000000 9 10A_v1 [4, 2, 0, 1, 3] 0.8000000 10 10A_v1 [4, 2, 0, 3, 1] 1.0000000 4 10A_v1 [4, 2, 1, 0, 3] 0.8571429 7 10A_v1 [4, 2, 1, 3, 0] 1.0000000 11 10A_v1 [4, 2, 3, 0, 1] 0.9166667 12 10A_v1 [4, 2, 3, 1, 0] 0.8000000 5 10A_v1 [4, 3, 0, 1, 2] 0.8000000 10 10A_v1 [4, 3, 0, 2, 1] 1.0000000 5 10A_v1 [4, 3, 1, 0, 2] 0.8181818 11 10A_v1 [4, 3, 1, 2, 0] 0.8333333 6 10A_v1 [4, 3, 2, 0, 1] 0.7500000 8 10A_v1 [4, 3, 2, 1, 0] 0.9166667 12 ### Histog ram theme_update(plot.title = element_text(hjust = 0.5)) ggplot(tena_v1, aes(x=p_value)) + geom_histogram(binwidth=.01) + labs(title = &quot;Item10A_v1&quot;) 3.3 Item 14b_v1 fourteenb_v1 = hp_items %&gt;% filter(item_id == &#39;14B_v1&#39;) kable(fourteenb_v1, format = &quot;markdown&quot;) item_id order p_value count 14B_v1 0 0.4235294 170 14B_v1 01 0.2765957 47 14B_v1 012 0.3636364 11 14B_v1 0123 0.2941176 17 14B_v1 01234 0.7049180 61 14B_v1 0124 0.7500000 12 14B_v1 013 0.5652174 23 14B_v1 0134 0.5666667 30 14B_v1 014 0.4583333 24 14B_v1 02 0.5263158 19 14B_v1 023 0.7500000 16 14B_v1 0234 0.4545455 11 14B_v1 024 0.6470588 17 14B_v1 03 0.4181818 55 14B_v1 034 0.5555556 36 14B_v1 04 0.4333333 30 14B_v1 1 0.0000000 39 14B_v1 12 0.0000000 23 14B_v1 123 0.0000000 22 14B_v1 1234 0.0000000 36 14B_v1 124 0.0000000 19 14B_v1 13 0.0000000 8 14B_v1 134 0.0000000 11 14B_v1 14 0.0000000 9 14B_v1 2 0.0000000 129 14B_v1 23 0.0000000 35 14B_v1 234 0.0000000 21 14B_v1 24 0.0000000 20 14B_v1 3 0.0000000 30 14B_v1 34 0.0000000 11 14B_v1 4 0.0000000 59 3.3.1 Histogram ggplot(fourteenb_v1, aes(x=p_value)) + geom_histogram(binwidth=.01) + labs(title = &quot;Item14B_v1&quot;)+ xlim(-.01,1) + ylim(0,20) 3.4 Item 14a_v1 fourteenb_v1 = hp_items_mc %&gt;% filter(item_id == &#39;14A_v1&#39;) kable(fourteenb_v1, format = &quot;markdown&quot;) item_id item_order p_value count 14A_v1 [0, 1, 2, 3, 4] 0.4285714 7 14A_v1 [0, 1, 2, 4, 3] 0.5000000 10 14A_v1 [0, 1, 3, 2, 4] 0.3000000 10 14A_v1 [0, 1, 3, 4, 2] 0.2000000 10 14A_v1 [0, 1, 4, 2, 3] 0.2500000 8 14A_v1 [0, 1, 4, 3, 2] 0.4444444 9 14A_v1 [0, 2, 1, 3, 4] 0.1250000 8 14A_v1 [0, 2, 1, 4, 3] 0.4285714 7 14A_v1 [0, 2, 3, 1, 4] 0.1428571 7 14A_v1 [0, 2, 3, 4, 1] 0.5555556 9 14A_v1 [0, 2, 4, 1, 3] 0.1250000 8 14A_v1 [0, 2, 4, 3, 1] 0.5714286 7 14A_v1 [0, 3, 1, 2, 4] 0.1428571 7 14A_v1 [0, 3, 1, 4, 2] 0.5000000 8 14A_v1 [0, 3, 2, 1, 4] 0.4545455 11 14A_v1 [0, 3, 2, 4, 1] 0.2500000 8 14A_v1 [0, 3, 4, 1, 2] 0.2500000 8 14A_v1 [0, 3, 4, 2, 1] 0.3000000 10 14A_v1 [0, 4, 1, 2, 3] 0.2500000 8 14A_v1 [0, 4, 1, 3, 2] 0.5555556 9 14A_v1 [0, 4, 2, 1, 3] 0.4000000 10 14A_v1 [0, 4, 2, 3, 1] 0.2857143 7 14A_v1 [0, 4, 3, 1, 2] 0.5500000 20 14A_v1 [0, 4, 3, 2, 1] 0.4285714 14 14A_v1 [1, 0, 2, 3, 4] 0.2222222 9 14A_v1 [1, 0, 2, 4, 3] 0.3750000 8 14A_v1 [1, 0, 3, 2, 4] 0.2857143 7 14A_v1 [1, 0, 3, 4, 2] 0.2500000 12 14A_v1 [1, 0, 4, 2, 3] 0.4000000 5 14A_v1 [1, 0, 4, 3, 2] 0.4285714 7 14A_v1 [1, 2, 0, 3, 4] 0.2727273 11 14A_v1 [1, 2, 0, 4, 3] 0.2857143 7 14A_v1 [1, 2, 3, 0, 4] 0.1111111 9 14A_v1 [1, 2, 3, 4, 0] 0.2000000 5 14A_v1 [1, 2, 4, 0, 3] 0.4444444 9 14A_v1 [1, 2, 4, 3, 0] 0.2500000 8 14A_v1 [1, 3, 0, 2, 4] 0.2727273 11 14A_v1 [1, 3, 0, 4, 2] 0.2000000 10 14A_v1 [1, 3, 2, 0, 4] 0.1428571 7 14A_v1 [1, 3, 2, 4, 0] 0.1333333 15 14A_v1 [1, 3, 4, 0, 2] 0.2500000 8 14A_v1 [1, 3, 4, 2, 0] 0.1818182 11 14A_v1 [1, 4, 0, 2, 3] 0.2307692 13 14A_v1 [1, 4, 0, 3, 2] 0.5714286 14 14A_v1 [1, 4, 2, 0, 3] 0.0000000 5 14A_v1 [1, 4, 2, 3, 0] 0.1250000 8 14A_v1 [1, 4, 3, 0, 2] 0.2000000 15 14A_v1 [1, 4, 3, 2, 0] 0.1666667 6 14A_v1 [2, 0, 1, 3, 4] 0.2500000 8 14A_v1 [2, 0, 1, 4, 3] 0.1428571 7 14A_v1 [2, 0, 3, 1, 4] 0.2727273 11 14A_v1 [2, 0, 3, 4, 1] 0.4615385 13 14A_v1 [2, 0, 4, 1, 3] 0.3750000 8 14A_v1 [2, 0, 4, 3, 1] 0.3333333 9 14A_v1 [2, 1, 0, 3, 4] 0.1428571 7 14A_v1 [2, 1, 0, 4, 3] 0.6666667 6 14A_v1 [2, 1, 3, 0, 4] 0.1666667 6 14A_v1 [2, 1, 3, 4, 0] 0.3333333 9 14A_v1 [2, 1, 4, 0, 3] 0.5714286 7 14A_v1 [2, 1, 4, 3, 0] 0.3000000 10 14A_v1 [2, 3, 0, 1, 4] 0.7000000 10 14A_v1 [2, 3, 0, 4, 1] 0.2000000 5 14A_v1 [2, 3, 1, 0, 4] 0.3750000 8 14A_v1 [2, 3, 1, 4, 0] 0.2727273 11 14A_v1 [2, 3, 4, 0, 1] 0.2727273 11 14A_v1 [2, 3, 4, 1, 0] 0.1818182 11 14A_v1 [2, 4, 0, 1, 3] 0.3750000 8 14A_v1 [2, 4, 0, 3, 1] 0.3636364 11 14A_v1 [2, 4, 1, 0, 3] 0.1428571 7 14A_v1 [2, 4, 1, 3, 0] 0.2000000 5 14A_v1 [2, 4, 3, 0, 1] 0.2000000 10 14A_v1 [2, 4, 3, 1, 0] 0.3636364 11 14A_v1 [3, 0, 1, 2, 4] 0.0000000 7 14A_v1 [3, 0, 1, 4, 2] 0.3333333 9 14A_v1 [3, 0, 2, 1, 4] 0.3333333 6 14A_v1 [3, 0, 2, 4, 1] 0.4166667 12 14A_v1 [3, 0, 4, 1, 2] 0.2857143 7 14A_v1 [3, 0, 4, 2, 1] 0.0000000 8 14A_v1 [3, 1, 0, 2, 4] 0.0000000 4 14A_v1 [3, 1, 0, 4, 2] 0.2727273 11 14A_v1 [3, 1, 2, 0, 4] 0.4000000 10 14A_v1 [3, 1, 2, 4, 0] 0.0909091 11 14A_v1 [3, 1, 4, 0, 2] 0.1666667 12 14A_v1 [3, 1, 4, 2, 0] 0.2000000 10 14A_v1 [3, 2, 0, 1, 4] 0.2500000 12 14A_v1 [3, 2, 0, 4, 1] 0.3333333 15 14A_v1 [3, 2, 1, 0, 4] 0.0909091 11 14A_v1 [3, 2, 1, 4, 0] 0.3076923 13 14A_v1 [3, 2, 4, 0, 1] 0.3000000 10 14A_v1 [3, 2, 4, 1, 0] 0.3750000 8 14A_v1 [3, 4, 0, 1, 2] 0.2222222 9 14A_v1 [3, 4, 0, 2, 1] 0.5833333 12 14A_v1 [3, 4, 1, 0, 2] 0.1666667 6 14A_v1 [3, 4, 1, 2, 0] 0.2000000 10 14A_v1 [3, 4, 2, 0, 1] 0.1818182 11 14A_v1 [3, 4, 2, 1, 0] 0.3333333 9 14A_v1 [4, 0, 1, 2, 3] 0.2500000 16 14A_v1 [4, 0, 1, 3, 2] 0.3750000 8 14A_v1 [4, 0, 2, 1, 3] 0.3333333 3 14A_v1 [4, 0, 2, 3, 1] 0.6666667 9 14A_v1 [4, 0, 3, 1, 2] 0.3333333 12 14A_v1 [4, 0, 3, 2, 1] 0.3636364 11 14A_v1 [4, 1, 0, 2, 3] 0.5000000 10 14A_v1 [4, 1, 0, 3, 2] 0.2500000 8 14A_v1 [4, 1, 2, 0, 3] 0.1666667 12 14A_v1 [4, 1, 2, 3, 0] 0.2000000 15 14A_v1 [4, 1, 3, 0, 2] 0.2727273 11 14A_v1 [4, 1, 3, 2, 0] 0.1764706 17 14A_v1 [4, 2, 0, 1, 3] 0.2222222 9 14A_v1 [4, 2, 0, 3, 1] 0.3000000 10 14A_v1 [4, 2, 1, 0, 3] 0.5000000 8 14A_v1 [4, 2, 1, 3, 0] 0.1875000 16 14A_v1 [4, 2, 3, 0, 1] 0.2500000 4 14A_v1 [4, 2, 3, 1, 0] 0.3333333 9 14A_v1 [4, 3, 0, 1, 2] 0.3333333 9 14A_v1 [4, 3, 0, 2, 1] 0.3333333 9 14A_v1 [4, 3, 1, 0, 2] 0.1428571 14 14A_v1 [4, 3, 1, 2, 0] 0.6666667 6 14A_v1 [4, 3, 2, 0, 1] 0.3750000 8 14A_v1 [4, 3, 2, 1, 0] 0.0833333 12 3.4.1 Histogram ggplot(fourteenb_v1, aes(x=p_value)) + geom_histogram(binwidth=.01) + labs(title = &quot;Item14A_v1&quot;)+ xlim(-.01,1) + ylim(0,20) 3.5 Remove correct response We notice quickly that it is pretty difficult to interpret the p-values given that there is a significant amount of peole who never see the correct answer so the p-value for those “children” is 0. Here is what happens when we redefine what it means to be a different item. Instead of looking at every combination of seen options we are only going to look at distractors. This means that someone who saw the correct option and the first option (coded 01) will have “seen” the “same” question as someone who just saw the first distractor(coded 1). It cleans things up a bit but it is important to recognize what is going on. hp_summary$order_no_cr = gsub(&#39;0&#39;,&#39;&#39;,hp_summary$order) hp_summary$order_no_cr = ifelse(hp_summary$order_no_cr == &#39;&#39;, &#39;0&#39;, hp_summary$order_no_cr) hp_items_no_cr = hp_summary %&gt;% group_by(item_id, order_no_cr) %&gt;% summarize(p_value = mean(score), count = n()) all_items = bind_rows(hp_items_no_cr, hp_items_mc) all_items$item_type = ifelse(is.na(all_items$item_order), &#39;DOMC&#39;, &quot;MC&quot;) all_items$item_number = as.numeric(str_extract(all_items$item_id, &quot;[0-9]+&quot;)) 3.6 Item 10B_v1 tenb_v1 = hp_items_no_cr %&gt;% filter(item_id == &#39;10B_v1&#39;) kable(tenb_v1) item_id order_no_cr p_value count 10B_v1 0 0.8950000 200 10B_v1 1 0.6666667 63 10B_v1 12 0.8108108 37 10B_v1 123 0.8333333 48 10B_v1 1234 0.9142857 175 10B_v1 124 0.9344262 61 10B_v1 13 0.7250000 40 10B_v1 134 0.8653846 52 10B_v1 14 0.7428571 35 10B_v1 2 0.8939394 66 10B_v1 23 0.9487179 39 10B_v1 234 0.9206349 63 10B_v1 24 0.8333333 42 10B_v1 3 0.9298246 57 10B_v1 34 0.9666667 30 10B_v1 4 0.9302326 43 3.6.1 Histogram theme_update(plot.title = element_text(hjust = 0.5)) ggplot(tenb_v1, aes(x=p_value)) + geom_histogram(binwidth=.01) + labs(title = &quot;Item10B_v1&quot;) + xlim(-.01,1) 3.7 Item 14b_v1 fourteenb_v1 = hp_items_no_cr %&gt;% filter(item_id == &#39;14B_v1&#39;) kable(fourteenb_v1) item_id order_no_cr p_value count 14B_v1 0 0.4235294 170 14B_v1 1 0.1511628 86 14B_v1 12 0.1176471 34 14B_v1 123 0.1282051 39 14B_v1 1234 0.4432990 97 14B_v1 124 0.2903226 31 14B_v1 13 0.4193548 31 14B_v1 134 0.4146341 41 14B_v1 14 0.3333333 33 14B_v1 2 0.0675676 148 14B_v1 23 0.2352941 51 14B_v1 234 0.1562500 32 14B_v1 24 0.2972973 37 14B_v1 3 0.2705882 85 14B_v1 34 0.4255319 47 14B_v1 4 0.1460674 89 theme_update(plot.title = element_text(hjust = 0.5)) ggplot(all_items %&gt;% filter(item_number == 14), aes(x=p_value, color=item_type)) + geom_histogram(fill=&#39;white&#39;, binwidth=.01, position=&#39;identity&#39;, alpha=0) + labs(title = &quot;Item14&quot;) + xlim(-.01,1) + geom_density() ## Warning: Removed 4 rows containing missing values (geom_bar). 3.7.1 Histogram ggplot(fourteenb_v1, aes(x=p_value)) + geom_histogram(binwidth=.01) + labs(title = &quot;Item14b_v1&quot;) + xlim(-.01,1) 3.8 All Item Plots knitr::opts_chunk$set(fig.width=12, fig.height=20) ggplot(all_items, aes(x=p_value, color=item_type)) + geom_histogram(fill=&#39;white&#39;, binwidth=.01, position=&#39;identity&#39;, alpha=0) + xlim(-.01,1) + geom_density() + labs(title = &quot;All Items&quot;) + xlim(-.01,1) +ylim(0,20) + facet_wrap(~item_number, ncol=3) "],
["domc-difficulty-factors.html", "4 DOMC Difficulty Factors", " 4 DOMC Difficulty Factors The purpose of this chapter is to briefly address portions of the item format that may lead to systematic differences in difficulty for DOMC items library(dplyr) library(readr) library(knitr) library(ggplot2) library(lemon) setwd_thisdir &lt;- function () { this.dir &lt;- dirname(parent.frame(3)$ofile) setwd(this.dir) } hp_data = read_csv(&#39;data/domc_order_difficulty/Full Responses After Exclusions.csv&#39;) ## Parsed with column specification: ## cols( ## delivery_id = col_character(), ## item_id = col_character(), ## item_type = col_character(), ## item_total_seconds = col_double(), ## score = col_double(), ## points_possible = col_double(), ## key = col_character(), ## option_presented = col_character(), ## response = col_double(), ## item_component_type = col_character(), ## item_component_seconds = col_double(), ## start_time = col_datetime(format = &quot;&quot;), ## end_time = col_datetime(format = &quot;&quot;) ## ) hp_clean = hp_data %&gt;% filter(item_type == &#39;domc&#39; | item_type == &#39;multiple_choice&#39;, item_component_type == &#39;domc_option&#39; | item_component_type == &#39;final&#39;, !grepl(&#39;Survey&#39;, hp_data$item_id)) %&gt;% group_by(delivery_id, item_id) %&gt;% mutate(option_order = paste0(option_presented, collapse = &quot;&quot;)) hp_summary = hp_clean %&gt;% group_by(delivery_id, item_id, item_type) %&gt;% summarize(item_total_seconds = max(item_total_seconds), item_order = max(option_order), score = max(score)) %&gt;% group_by(delivery_id, item_id) %&gt;% mutate(order = paste(sort(unlist(strsplit(as.character(item_order), &quot;&quot;))), collapse = &quot;&quot;)) %&gt;% ungroup() total_score = hp_summary %&gt;% group_by(delivery_id) %&gt;% summarize(total_score = sum(score)) hp_final = left_join(hp_summary, total_score) ## Joining, by = &quot;delivery_id&quot; hp_final$char_count = nchar(hp_final$order) "],
["total-test-score-and-options-seen.html", "5 Total Test Score and Options Seen", " 5 Total Test Score and Options Seen Simply running a logistic regression predicting if a person will get an item correct based on teh total number of options seen seems disingenous for a DOMC item. The reason being is that more proficient examinees will on average see more options as they are more likely to reject incorrect options. Here we look at some regression results mylogit &lt;- glm(score ~ total_score + factor(item_type) + char_count, data = hp_final, family = &quot;binomial&quot;) summary(mylogit) ## ## Call: ## glm(formula = score ~ total_score + factor(item_type) + char_count, ## family = &quot;binomial&quot;, data = hp_final) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.4972 -1.0727 0.6177 0.8451 2.3305 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -3.587105 0.055005 -65.21 &lt;2e-16 *** ## total_score 0.217796 0.003298 66.04 &lt;2e-16 *** ## factor(item_type)multiple_choice -6.181737 0.160348 -38.55 &lt;2e-16 *** ## char_count 0.504366 0.012474 40.43 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 59053 on 45758 degrees of freedom ## Residual deviance: 51520 on 45755 degrees of freedom ## AIC: 51528 ## ## Number of Fisher Scoring iterations: 4 mylogit &lt;- glm(score ~ factor(item_type) + char_count + factor(item_type)*char_count, data = hp_final, family = &quot;binomial&quot;) summary(mylogit) ## ## Call: ## glm(formula = score ~ factor(item_type) + char_count + factor(item_type) * ## char_count, family = &quot;binomial&quot;, data = hp_final) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.0489 -1.3260 0.8314 0.8926 1.2630 ## ## Coefficients: (1 not defined because of singularities) ## Estimate Std. Error z value ## (Intercept) -0.74081 0.03029 -24.46 ## factor(item_type)multiple_choice -6.67167 0.15294 -43.62 ## char_count 0.54180 0.01188 45.61 ## factor(item_type)multiple_choice:char_count NA NA NA ## Pr(&gt;|z|) ## (Intercept) &lt;2e-16 *** ## factor(item_type)multiple_choice &lt;2e-16 *** ## char_count &lt;2e-16 *** ## factor(item_type)multiple_choice:char_count NA ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 59053 on 45758 degrees of freedom ## Residual deviance: 56570 on 45756 degrees of freedom ## AIC: 56576 ## ## Number of Fisher Scoring iterations: 4 "],
["recall-vs-deduction.html", "6 Recall VS Deduction 6.1 Some Graphs", " 6 Recall VS Deduction In this chapter we will look at some differences between recall and deduction items on a Harry Potter assessment. library(dplyr) library(readr) library(knitr) library(ggplot2) library(lemon) library(stringr) setwd_thisdir &lt;- function () { this.dir &lt;- dirname(parent.frame(3)$ofile) setwd(this.dir) } hp_data = read_csv(&#39;data/domc_order_difficulty/Full Responses After Exclusions.csv&#39;) ## Parsed with column specification: ## cols( ## delivery_id = col_character(), ## item_id = col_character(), ## item_type = col_character(), ## item_total_seconds = col_double(), ## score = col_double(), ## points_possible = col_double(), ## key = col_character(), ## option_presented = col_character(), ## response = col_double(), ## item_component_type = col_character(), ## item_component_seconds = col_double(), ## start_time = col_datetime(format = &quot;&quot;), ## end_time = col_datetime(format = &quot;&quot;) ## ) hp_clean = hp_data %&gt;% filter(item_type == &#39;domc&#39; | item_type == &#39;multiple_choice&#39;, item_component_type == &#39;domc_option&#39; | item_component_type == &#39;final&#39;, !grepl(&#39;Survey&#39;, hp_data$item_id)) %&gt;% group_by(delivery_id, item_id) %&gt;% mutate(option_order = paste0(option_presented, collapse = &quot;&quot;)) recall &lt;- c(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;5&quot;, &quot;6&quot;, &quot;7&quot;, &quot;8&quot;, &quot;9&quot;, &quot;10&quot;, &quot;11&quot;, &quot;12&quot;) deduction = c(&quot;13&quot;, &quot;14&quot;, &quot;15&quot;, &quot;16&quot;, &quot;17&quot;, &quot;18&quot;, &quot;19&quot;, &quot;20&quot;, &quot;21&quot;, &quot;22&quot;) hp_clean$deduction &lt;- ifelse(grepl(paste(deduction,collapse=&quot;|&quot;), hp_clean$item_id),1,0) hp_items = hp_clean %&gt;% group_by(item_id, item_type) %&gt;% summarize(p_value = mean(score), count = n(), deduction = mean(deduction,na.rm=TRUE)) hp_items$item_number = str_extract(hp_items$item_id, &quot;[0-9]+&quot;) 6.1 Some Graphs Here is the difference in p-value between DOMC and multiple choice for the same items. #here ggplot(hp_items, aes(x=item_type, y=p_value, fill=item_type)) + geom_bar(stat=&quot;identity&quot;) + facet_wrap(~item_number) Here is the difference in p-value between DOMC and multiple choice for the same items. just_mc = hp_items %&gt;% filter(item_type == &#39;multiple_choice&#39;) just_domc = hp_items %&gt;% filter(item_type != &#39;multiple_choice&#39;) differences = hp_items %&gt;% group_by(item_type) %&gt;% summarize(average_p_value = mean(p_value, na.rm=TRUE)) kable(differences) item_type average_p_value domc 0.6933272 multiple_choice 0.6741205 The total difference in p-values between item_types is -0.0192067. Multiple Choice items appear to be slightly more difficult. "],
["whocares.html", "7 whocares", " 7 whocares "],
["references.html", "References", " References "],
["simulation-1.html", "8 Simulation 1 8.1 Generating Data 8.2 Test Differences", " 8 Simulation 1 In this chapter we will be talking about different simualtions run to address potential issues with smart items. To begin we are going to look at how test composition and difficulty change when people are administered random items from an item pool instead of a fixed form test. 8.1 Generating Data We generated a bank of 5000 items using the 2 prameter logistic model. The item difficulties were sampled from a normal distribution with a mean 0 and standard deviation of 1. The discrimination parameter was sampled from a normal distribution with mean 1 and a standard deviation of .05. We then generated 100,000 examinees and had each examinee take tests comprised of random items from length 10 to 60 In addition to 50 random forms, each examinee took a fixed form test comprised of the same 40 items for each of the 100,000 examinees. 8.2 Test Differences It was important to come up with a way to determine if the random form was of differing difficulty than the 40 item fixed form test. How we did this was by computing the standard error of test difficulty using the p-values for items on the fixed form test. This was used to compute a confidence interval for the test difficulty. The standard error was st_dev/sqrt(test_length) = .028. Using a 95% confidence interval we see that the confidence interval for the difficulty of hte fixed form test is from .44 to .55. Now, whenever a candidate took a random form test we compared the difficulty of that test to the confidence interval above. If the difficulty of their test fell within the confidence interval we decided that this meant the random form test was no different in diffculty from the fixed form test. There were several different ways of determining if a person received tests of different difficulties. The above method is simply one of the different ways of doing so. Finally, we computed the percent of individuals at each item count that had a similar or different difficulty test. As we can see in the following table. When the random test was only 10 items long, 62% of candidates had a test that was either harder or easier than the 40 item fixed test. However, by the time the random test was 40 items long only 2% of people had a test that was either harder or easier than the fixed form test. As the number of items on the random test increased, the probability of it being a different diffculty test decreased. kable(item_count_group) item_count test_change_difficulty count 10 0.6226226 999 11 0.5485485 999 12 0.5545546 999 13 0.4624625 999 14 0.4444444 999 15 0.3783784 999 16 0.3083083 999 17 0.3523524 999 18 0.3143143 999 19 0.3103103 999 20 0.2822823 999 21 0.2302302 999 22 0.2122122 999 23 0.2262262 999 24 0.1461461 999 25 0.1821822 999 26 0.1361361 999 27 0.1481481 999 28 0.1201201 999 29 0.1001001 999 30 0.0980981 999 31 0.0820821 999 32 0.0700701 999 33 0.0740741 999 34 0.0520521 999 35 0.0680681 999 36 0.0740741 999 37 0.0500501 999 38 0.0460460 999 39 0.0260260 999 40 0.0200200 999 41 0.0280280 999 42 0.0280280 999 43 0.0260260 999 44 0.0200200 999 45 0.0180180 999 46 0.0160160 999 47 0.0180180 999 48 0.0100100 999 49 0.0200200 999 50 0.0020020 999 51 0.0060060 999 52 0.0040040 999 53 0.0040040 999 54 0.0040040 999 55 0.0040040 999 56 0.0040040 999 57 0.0000000 999 58 0.0060060 999 59 0.0000000 999 "],
["simulation-2.html", "9 Simulation 2", " 9 Simulation 2 The first simulation showed that increasing the number of items on the random test resulted in more tests being equivilent in difficulty. However, one important part of many tests is evaluating what happens with the cut score decision. Tests arent 100% precise and their inprecision is captured in the reliability statistic. If a person took the test again tehy would not get the exact same score but hopefully get a similar score. However, the differences in the two different test scores may cross over the cut score decision so in one case they may pass and in another they may fail. When tests can also vary in difficulty it is possible that the change in the difficulty of hte test will result in larger numbers of people getting different cut score classifications because they recieved a different difficulty test. In this second simulation we are going to expand on the data from the first simulation. We generated the data in the exact same way with one exception: we added in a modified angoff cut score to each of the 5000 items. This angoff cut score was generated by simply sampling a value from a normal distribution with a mean 15% easier than the item itself and a standard deviation of .05. So if an item had a p-value of .5, the cut score for the item would be sampled from a normal distribution from mean .65 and a standard deviation of .05. This made a test where the cut score was slightly lower than the average difficulty of the items on the test. Each simulated examinee then took the random tests of varying length and the fixed form test and whether they passed each test based on the items in that test. If they got a different cut score decision on the fixed form test than the random test then there was a cut score classification change. We took extra care to look at cut score classification changes when an examinee passed the fixed test, recieved a harder random test and did not pass. We then evaluated the percent of people with classification changes and the precent of people with classification changes when given a harder random form test. The results are reported in the table below. There are several important things to note in the table. The number of people who get a similar difficulty test but a different cut score classification is not zero. The number of people who recieve a similar difficulty test but a different cut score classification goes down as the number of items increases. The same is true for people with a different difficulty test. As the number of items increased, the number of people getting a different cut score classification and a different difficulty test shrinks For around a random test around similar length as the fixed test only about .2% of people are recieving a different difficuly test AND also getting a different cut score classification. It is important to not that around 7% of people who got a simialr difficulty test got different cut score classifications. When considering unfairness on a test where a cut score decision is used only a very small percentage of people get both a different difficulty of test and a different cut score classification. kable(item_class_change) item_count test_change_difficulty decision_change count freq 10 0 0 570 0.5705706 10 0 1 118 0.1181181 10 1 0 252 0.2522523 10 1 1 59 0.0590591 11 0 0 617 0.6176176 11 0 1 108 0.1081081 11 1 0 215 0.2152152 11 1 1 59 0.0590591 12 0 0 612 0.6126126 12 0 1 110 0.1101101 12 1 0 218 0.2182182 12 1 1 59 0.0590591 13 0 0 663 0.6636637 13 0 1 105 0.1051051 13 1 0 191 0.1911912 13 1 1 40 0.0400400 14 0 0 661 0.6616617 14 0 1 116 0.1161161 14 1 0 179 0.1791792 14 1 1 43 0.0430430 15 0 0 700 0.7007007 15 0 1 110 0.1101101 15 1 0 156 0.1561562 15 1 1 33 0.0330330 16 0 0 741 0.7417417 16 0 1 104 0.1041041 16 1 0 131 0.1311311 16 1 1 23 0.0230230 17 0 0 740 0.7407407 17 0 1 83 0.0830831 17 1 0 153 0.1531532 17 1 1 23 0.0230230 18 0 0 750 0.7507508 18 0 1 92 0.0920921 18 1 0 135 0.1351351 18 1 1 22 0.0220220 19 0 0 755 0.7557558 19 0 1 89 0.0890891 19 1 0 129 0.1291291 19 1 1 26 0.0260260 20 0 0 760 0.7607608 20 0 1 98 0.0980981 20 1 0 124 0.1241241 20 1 1 17 0.0170170 21 0 0 780 0.7807808 21 0 1 104 0.1041041 21 1 0 99 0.0990991 21 1 1 16 0.0160160 22 0 0 782 0.7827828 22 0 1 111 0.1111111 22 1 0 92 0.0920921 22 1 1 14 0.0140140 23 0 0 782 0.7827828 23 0 1 104 0.1041041 23 1 0 95 0.0950951 23 1 1 18 0.0180180 24 0 0 832 0.8328328 24 0 1 94 0.0940941 24 1 0 64 0.0640641 24 1 1 9 0.0090090 25 0 0 807 0.8078078 25 0 1 101 0.1011011 25 1 0 79 0.0790791 25 1 1 12 0.0120120 26 0 0 836 0.8368368 26 0 1 95 0.0950951 26 1 0 56 0.0560561 26 1 1 12 0.0120120 27 0 0 833 0.8338338 27 0 1 92 0.0920921 27 1 0 63 0.0630631 27 1 1 11 0.0110110 28 0 0 859 0.8598599 28 0 1 80 0.0800801 28 1 0 45 0.0450450 28 1 1 15 0.0150150 29 0 0 869 0.8698699 29 0 1 80 0.0800801 29 1 0 46 0.0460460 29 1 1 4 0.0040040 30 0 0 851 0.8518519 30 0 1 99 0.0990991 30 1 0 40 0.0400400 30 1 1 9 0.0090090 31 0 0 862 0.8628629 31 0 1 96 0.0960961 31 1 0 40 0.0400400 31 1 1 1 0.0010010 32 0 0 887 0.8878879 32 0 1 77 0.0770771 32 1 0 29 0.0290290 32 1 1 6 0.0060060 33 0 0 879 0.8798799 33 0 1 83 0.0830831 33 1 0 34 0.0340340 33 1 1 3 0.0030030 34 0 0 882 0.8828829 34 0 1 91 0.0910911 34 1 0 25 0.0250250 34 1 1 1 0.0010010 35 0 0 877 0.8778779 35 0 1 88 0.0880881 35 1 0 29 0.0290290 35 1 1 5 0.0050050 36 0 0 882 0.8828829 36 0 1 80 0.0800801 36 1 0 30 0.0300300 36 1 1 7 0.0070070 37 0 0 902 0.9029029 37 0 1 72 0.0720721 37 1 0 22 0.0220220 37 1 1 3 0.0030030 38 0 0 879 0.8798799 38 0 1 97 0.0970971 38 1 0 23 0.0230230 39 0 0 900 0.9009009 39 0 1 86 0.0860861 39 1 0 13 0.0130130 40 0 0 909 0.9099099 40 0 1 80 0.0800801 40 1 0 10 0.0100100 41 0 0 908 0.9089089 41 0 1 77 0.0770771 41 1 0 14 0.0140140 42 0 0 907 0.9079079 42 0 1 78 0.0780781 42 1 0 13 0.0130130 42 1 1 1 0.0010010 43 0 0 901 0.9019019 43 0 1 85 0.0850851 43 1 0 11 0.0110110 43 1 1 2 0.0020020 44 0 0 913 0.9139139 44 0 1 76 0.0760761 44 1 0 8 0.0080080 44 1 1 2 0.0020020 45 0 0 914 0.9149149 45 0 1 76 0.0760761 45 1 0 8 0.0080080 45 1 1 1 0.0010010 46 0 0 915 0.9159159 46 0 1 76 0.0760761 46 1 0 7 0.0070070 46 1 1 1 0.0010010 47 0 0 923 0.9239239 47 0 1 67 0.0670671 47 1 0 6 0.0060060 47 1 1 3 0.0030030 48 0 0 903 0.9039039 48 0 1 91 0.0910911 48 1 0 5 0.0050050 49 0 0 916 0.9169169 49 0 1 73 0.0730731 49 1 0 9 0.0090090 49 1 1 1 0.0010010 50 0 0 915 0.9159159 50 0 1 83 0.0830831 50 1 0 1 0.0010010 51 0 0 920 0.9209209 51 0 1 76 0.0760761 51 1 0 3 0.0030030 52 0 0 920 0.9209209 52 0 1 77 0.0770771 52 1 0 2 0.0020020 53 0 0 916 0.9169169 53 0 1 81 0.0810811 53 1 0 2 0.0020020 54 0 0 932 0.9329329 54 0 1 65 0.0650651 54 1 0 2 0.0020020 55 0 0 941 0.9419419 55 0 1 56 0.0560561 55 1 0 2 0.0020020 56 0 0 940 0.9409409 56 0 1 57 0.0570571 56 1 0 2 0.0020020 57 0 0 927 0.9279279 57 0 1 72 0.0720721 58 0 0 943 0.9439439 58 0 1 53 0.0530531 58 1 0 3 0.0030030 59 0 0 922 0.9229229 59 0 1 77 0.0770771 "],
["future-simulations.html", "10 Future Simulations", " 10 Future Simulations Obviously a simulation only works well if it the assumptions in data generation are reflective of reality and every simiulation has faults that can be addressed by adding in more information. Future simulations would include: How is the cut score classification change impacted by different methods of generating angoff style cut scores for each item (for example, if the sample was not .15 easier than the item but instead was sample with a mean of 0 and sd .5) How does the change in the discrimination parameter during the data generation process affect results. For example, if our items did not discriminate at 1 on average but instead .5? What if there is a larger difference between the ability distribution and the item difficulty distribution? What happens if instead of sampling items at random from the item pool you sample items whose scores correlate with eachother more than with the other items. This would be a better example of smart items where each item generated by smart item code would correlate more closely with other item generaged using the same code than every other item on the test. "]
]
